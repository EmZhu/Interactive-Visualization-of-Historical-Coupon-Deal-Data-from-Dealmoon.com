temp = merge(popularity_overall, popularity_by_category, by='Category')
View(temp)
popularity_data = merge(popularity_overall, popularity_by_category, by = 'Category')
popularity_by_category = deal_data %>% group_by(Category) %>% summarise(Total = sum(Popularity))
popularity_data = merge(popularity_overall, popularity_by_category, by = 'Category')
View(popularity_data)
popularity_data$Ratio = popularity_data$Popularity / popularity_data$Total
Top_5 = popularity_data %>% group_by(Category) %>% top_n(5, Ratio)
View(Top_5)
popularity_overall = deal_data %>% group_by(Category, Store) %>% summarise(Popularity = sum(Popularity), NumDeals = sum(Store))
popularity_overall = deal_data %>% group_by(Category, Store) %>% summarise(Popularity = sum(Popularity), NumDeals = count(Store))
popularity_overall = deal_data %>% group_by(Category, Store) %>% summarise(Popularity = sum(Popularity), NumDeals = n(Store))
popularity_overall = deal_data %>% group_by(Category, Store) %>% summarise(Popularity = sum(Popularity), NumDeals = n())
View(popularity_overall)
popularity_overall = deal_data %>% group_by(Category, Store) %>% summarise(NumDeals = n(), Popularity = sum(Popularity))
popularity_by_category = deal_data %>% group_by(Category) %>% summarise(Total = sum(Popularity))
popularity_data = merge(popularity_overall, popularity_by_category, by = 'Category')
popularity_data$PPD = popularity_data$Popularity / popularity_data$NumDeals
Top_5 = popularity_data %>% group_by(Category) %>% top_n(5, PPD)
grep('MULTIPLESTORE', deal_data$Store)
deal_data$Store[-grep('MULTIPLESTORE', deal_data$Store)]
deal_data = deal_data[-grep('MULTIPLESTORE', deal_data$Store)]
View(deal_data)
deal_data[-grep('MULTIPLESTORE', deal_data$Store)]
grep('MULTIPLESTORE', deal_data$Store)
deal_data = deal_data[-grep('MULTIPLESTORE', deal_data$Store)]
deal_data = deal_data[-grep('MULTIPLESTORE', deal_data$Store), ]
deal_data = deal_data[-grep('MULTIPLESTORES', deal_data$Store), ]
View(deal_data)
deal_data = my_read_csv('Dealmoon_data/Deal_data.csv')
View(deal_data)
grep('MULTIPLESTORES', deal_data$Store)
[-grep('MULTIPLESTORE', deal_data$Store), ]
deal_data = deal_data[-grep('MULTIPLESTORE', deal_data$Store), ]
deal_data = deal_data[-grep('MULTIPLESTORES', deal_data$Store), ]
deal_data = my_read_csv('Dealmoon_data/Deal_data.csv')
deal_data = deal_data[-grep('MULTIPLESTORES', deal_data$Store), ]
# replace all store names that contain "Amazon" with "Amazon"
deal_data$Store[grep('AMAZON', deal_data$Store)] = 'AMAZON'
# replace all store names that contain "BESTBUY" with "BESTBUY"
deal_data$Store[grep("BESTBUY", deal_data$Store)] = "BESTBUY"
# strip away 'TODAYONLY#' from all store names
deal_data$Store = sub('^TODAYONLY[0-9]*', '', deal_data$Store)
# strip away 'TODAY#' from all store names
deal_data$Store = sub('^TODAY[0-9]*', '', deal_data$Store)
popularity_overall = deal_data %>% group_by(Category, Store) %>% summarise(NumDeals = n(), Popularity = sum(Popularity))
popularity_by_category = deal_data %>% group_by(Category) %>% summarise(Total = sum(Popularity))
popularity_data = merge(popularity_overall, popularity_by_category, by = 'Category')
popularity_data$PPD = popularity_data$Popularity / popularity_data$NumDeals
Top_5 = popularity_data %>% group_by(Category) %>% top_n(5, PPD)
my_read_csv2 = function (filename,
header = T,
colClasses = c('factor', 'character', 'character', 'integer', 'integer', 'character')) {
return(read.csv(filename, header = header, colClasses = colClasses))
}
deal_data = my_read_csv2('Dealmoon_data/Deal_data.csv')
# replace all store names that contain "Amazon" with "Amazon"
deal_data$Store[grep('AMAZON', deal_data$Store)] = 'AMAZON'
# replace all store names that contain "BESTBUY" with "BESTBUY"
deal_data$Store[grep("BESTBUY", deal_data$Store)] = "BESTBUY"
# strip away 'TODAYONLY#' from all store names
deal_data$Store = sub('^TODAYONLY[0-9]*', '', deal_data$Store)
# strip away 'TODAY#' from all store names
deal_data$Store = sub('^TODAY[0-9]*', '', deal_data$Store)
# remove 'MULTIPLESTORE' and 'MULTIPLESTORES'
deal_data = deal_data[-grep('MULTIPLESTORES', deal_data$Store), ]
#--------- Clean 'Time'
# Change all 'Time' with unit other than 'day' to '0 day'
deal_data$PostedTime[setdiff(setdiff(1:num_rows, grep('day', deal_data$PostedTime)), grep('days', deal_data$PostedTime))] = '0 day'
# strip off 'day' and 'days', so the entire column is numeric
deal_data$PostedTime = sub('[^[:digit:]]+', '', deal_data$PostedTime)
# change column class to integer
deal_data$PostedTime = as.integer(deal_data$PostedTime)
my_read_csv2 = function (filename,
header = T,
colClasses = c('factor', 'character', 'character', 'integer', 'integer', 'integer', 'character', 'integer')) {
return(read.csv(filename, header = header, colClasses = colClasses))
}
deal_data = my_read_csv2('Dealmoon_data/Deal_data.csv')
# replace all store names that contain "Amazon" with "Amazon"
deal_data$Store[grep('AMAZON', deal_data$Store)] = 'AMAZON'
# replace all store names that contain "BESTBUY" with "BESTBUY"
deal_data$Store[grep("BESTBUY", deal_data$Store)] = "BESTBUY"
# strip away 'TODAYONLY#' from all store names
deal_data$Store = sub('^TODAYONLY[0-9]*', '', deal_data$Store)
# strip away 'TODAY#' from all store names
deal_data$Store = sub('^TODAY[0-9]*', '', deal_data$Store)
# remove 'MULTIPLESTORE' and 'MULTIPLESTORES'
deal_data = deal_data[-grep('MULTIPLESTORES', deal_data$Store), ]
write.csv(deal_data2, 'Dealmoon_data/Deal_data.csv', row.names=F)
write.csv(deal_data, 'Dealmoon_data/Deal_data2.csv', row.names=F)
popularity_overall = deal_data %>% group_by(Category, Store) %>% summarise(NumDeals = n(), Popularity = sum(Popularity))
popularity_by_category = deal_data %>% group_by(Category) %>% summarise(Total = sum(Popularity))
popularity_data = merge(popularity_overall, popularity_by_category, by = 'Category')
popularity_data$PPD = popularity_data$Popularity / popularity_data$NumDeals
Top_5 = popularity_data %>% group_by(Category) %>% top_n(5, PPD)
deal_data = deal_data[-grep('VARIOUSSTORES', deal_data$Store), ]
write.csv(deal_data, 'Dealmoon_data/Deal_data2.csv', row.names=F)
popularity_overall = deal_data %>% group_by(Category, Store) %>% summarise(NumDeals = n(), Popularity = sum(Popularity))
popularity_by_category = deal_data %>% group_by(Category) %>% summarise(Total = sum(Popularity))
popularity_data = merge(popularity_overall, popularity_by_category, by = 'Category')
popularity_data$PPD = popularity_data$Popularity / popularity_data$NumDeals
Top_5 = popularity_data %>% group_by(Category) %>% top_n(5, PPD)
deal_data = deal_data[-grep('MULTIPLESTORE', deal_data$Store), ]
write.csv(deal_data, 'Dealmoon_data/Deal_data2.csv', row.names=F)
popularity_overall = deal_data %>% group_by(Category, Store) %>% summarise(NumDeals = n(), Popularity = sum(Popularity))
popularity_by_category = deal_data %>% group_by(Category) %>% summarise(Total = sum(Popularity))
popularity_data = merge(popularity_overall, popularity_by_category, by = 'Category')
popularity_data$PPD = popularity_data$Popularity / popularity_data$NumDeals
Top_5 = popularity_data %>% group_by(Category) %>% top_n(5, PPD)
Top_5 = popularity_data %>% group_by(Category) %>% filter(NumDeals >= 5) %>% top_n(5, PPD)
# replace all store names that contain "GNC" with "GNC"
deal_data$Store[grep("GNC", deal_data$Store)] = "GNC"
popularity_overall = deal_data %>% group_by(Category, Store) %>% summarise(NumDeals = n(), Popularity = sum(Popularity))
popularity_by_category = deal_data %>% group_by(Category) %>% summarise(Total = sum(Popularity))
popularity_data = merge(popularity_overall, popularity_by_category, by = 'Category')
popularity_data$PPD = popularity_data$Popularity / popularity_data$NumDeals
Top_5 = popularity_data %>% group_by(Category) %>% filter(NumDeals >= 5) %>% top_n(5, PPD)
Top_5 = popularity_data %>% group_by(Category) %>% filter(NumDeals >= 3) %>% top_n(5, PPD)
Top_5 = popularity_data %>% group_by(Category) %>% filter(NumDeals >= 5) %>% top_n(5, PPD)
write.csv(deal_data, 'Dealmoon_data/Deal_data2.csv', row.names=F)
Top_5_freq = popularity_overall %>% top_n(5, NumDeals)
View(Top_5_freq)
Top_5_PPD = popularity_data %>% group_by(Category) %>% filter(NumDeals >= 5) %>% top_n(5, PPD)
Top_5_deal = deal_data %>% group_by(Category) %>% top_n(5, Popularity)
View(Top_5_deal)
Top_5_deal = deal_data %>% group_by(Category) %>% top_n(5, Popularity) %>% select(Category, Title, Popularity)
Top_5_deal = deal_data %>% group_by(Category) %>% order(PostedTime) %>% top_n(5, Popularity) %>% select(Category, Title, Popularity)
Top_5_deal = deal_data %>% group_by(Category) %>% top_n(5, Popularity) %>% select(Category, PostedTime, Title, Popularity)
duplicated(deal_data$Description)
sum(duplicated(deal_data$Description))
duplicates = deal_data[duplicated(deal_data$Description),]
View(duplicates)
data.table(duplicates)
library(data.table)
data.table(duplicates)
today <- Sys.Date()
format(today, format="%B %d %Y")
today <- Sys.Date()
today  <- format(today, format="%B %d %Y")
today
today + 30
today = as.Date(today)
today <- Sys.Date()
today  <- format(today, format="%B %d %Y")
today = Sys.Date()
today
today + 30
as.Date('2016-08-13')
a = as.Date('2016-08-13')
a + 1
deal_data$PostedTime = deal_data$PostedTime + as.Date('2016-08-13')
write.csv(deal_data, 'Dealmoon_data/Deal_data2.csv', row.names=F)
temp = duplicates %>% group_by(Description)
View(temp)
duplicates %>% group_by(Description)
last = deal_data[duplicated(deal_data$Description, fromLast=T),]
warnings()
last = deal_data[duplicated(deal_data$Description, fromLast=T),]
View(last)
duplicated = deal_data[duplicated(deal_data$Description),]
duplicate_deals = deal_data[duplicated(deal_data$Description),]
non_duplicate_deals = deal_data[!duplicated(deal_data), ]
nrow(non_duplicate_deals)
non_duplicate_deals = deal_data[!unique(deal_data$Description), ]
non_duplicate_deals = deal_data[!duplicated(deal_data$Description), ]
nrow(non_duplicate_deals)
deal_data %>% group_by(Description) %>% summarise(length(Description))
nrow(deal_data[duplicated(deal_data$Description),])
duplicate_deals = dupldeal_data %>% group_by(Description) %>% summarise(length(Description))
duplicate_deals = deal_data %>% group_by(Description) %>% summarise(length(Description))
View(duplicate_deals)
duplicate_deals = deal_data %>% group_by(Description) %>% summarise(NumDuplicates = length(Description)) %>% filter(NumDuplicates > 1)
duplicate_deals = deal_data %>% group_by(Description) %>% select(Category, Title, PostedTime) summarise(NumDuplicates = length(Description)) %>% filter(NumDuplicates > 1)
duplicate_deals = deal_data %>% group_by(Description) %>% select(Category, Title, PostedTime) %>% summarise(NumDuplicates = length(Description)) %>% filter(NumDuplicates > 1)
duplicate_deals = deal_data %>% group_by(Description) %>% select(Category, Title, PostedTime, Description) %>% summarise(NumDuplicates = length(Description)) %>% filter(NumDuplicates > 1)
View(duplicate_deals)
duplicate_deals = deal_data %>% group_by(Description) %>% summarise(NumDuplicates = length(Description), Title) %>% filter(NumDuplicates > 1)
duplicate_deals = deal_data %>% group_by(Description) %>% summarise(NumDuplicates = length(Description), Title = Title) %>% filter(NumDuplicates > 1)
duplicate_deals = deal_data %>% group_by(Description) %>% summarise(NumDuplicates = length(Description)) %>% select(Title) %>% filter(NumDuplicates > 1)
duplicate_deals = deal_data %>% group_by(Description)
duplicate_deals = deal_data %>% group_by(Description) %>% summarise(NumDuplicates = length(Description)) %>% filter(NumDuplicates > 1)
View(duplicate_deals)
hist(duplicate_deals$NumDuplicates)
hist(duplicate_deals$NumDuplicates, xlim = c(min(duplicate_deals$NumDuplicates), max(duplicate_deals$NumDuplicates)))
range(3,6)
hist(duplicate_deals$NumDuplicates, xlim = range(min(duplicate_deals$NumDuplicates), max(duplicate_deals$NumDuplicates)))
hist(duplicate_deals$NumDuplicates, xlim = 10)
hist(duplicate_deals$NumDuplicates,10)
hist(duplicate_deals$NumDuplicates, xlim = c(2, 10), plot=T)
hist(duplicate_deals$NumDuplicates, xlim = c(2, 10))
hist(duplicate_deals$NumDuplicates, xlim = c(2, 10))
hist(duplicate_deals$NumDuplicates, xlim = c(2, 8))
hist(duplicate_deals$NumDuplicates, xlim = c(2:8))
hist(duplicate_deals$NumDuplicates, xlim = 2:8)
hist(duplicate_deals$NumDuplicates, xlim = c(2, 8))
hist(duplicate_deals$NumDuplicates, breaks = 6, xlim = c(2, 8))
hist(duplicate_deals$NumDuplicates)
hist(duplicate_deals$NumDuplicates, xlim = c(2,4))
hist(duplicate_deals$NumDuplicates, breaks = 3xlim = c(2,4))
hist(duplicate_deals$NumDuplicates, breaks = 3, xlim = c(2,4))
hist(duplicate_deals$NumDuplicates, breaks = 3, xlim = c(2,4))
hist(duplicate_deals$NumDuplicates)
count(duplicate_deals$NumDuplicates)
count(duplicate_deals$NumDuplicates)
dist(duplicate_deals$NumDuplicates)
barplot(duplicate_deals$NumDuplicates)
hist(duplicate_deals$NumDuplicates)
hist(duplicate_deals$NumDuplicates, breaks=4, xlim = c(2,5))
hist(duplicate_deals$NumDuplicates, breaks=4, xlim = c(2,6))
hist(duplicate_deals$NumDuplicates, breaks=4, xlim = c(2,7))
hist(duplicate_deals$NumDuplicates, breaks=4, xlim = c(2,4))
max(duplicate_deals$NumDuplicates)
range(duplicate_deals$NumDuplicates)
write.csv(non_duplicate_deals, 'Dealmoon_data/Non_duplicates.csv', row.names=F)
with_duplicates = deal_data
deal_data = deal_data[!duplicated(deal_data$Description), ]
deal_data = with_duplicates[!duplicated(with_duplicates$Description), ]
nrow(deal_data)
popularity_overall = deal_data %>% group_by(Category, Store) %>% summarise(NumDeals = n(), Popularity = sum(Popularity))
popularity_by_category = deal_data %>% group_by(Category) %>% summarise(Total = sum(Popularity))
popularity_data = merge(popularity_overall, popularity_by_category, by = 'Category')
popularity_data$PPD = popularity_data$Popularity / popularity_data$NumDeals
# Rank deals by popularity in each category
Top_5_deal = deal_data %>% group_by(Category) %>% top_n(5, Popularity) %>% select(Category, PostedTime, Title, Popularity)
View(Top_5_deal)
Top_5_freq = popularity_overall %>% top_n(5, NumDeals)
View(Top_5_freq)
Top_5_PPD = popularity_data %>% group_by(Category) %>% filter(NumDeals >= 5) %>% top_n(5, PPD)
View(Top_5_PPD)
most_duplicated = duplicate_deals[which.max(duplicate_deals$NumDuplicates)]
View(duplicate_deals)
duplicate_deals = deal_data %>% group_by(Description) %>% summarise(NumDuplicates = length(Description)) %>% filter(NumDuplicates > 1)
most_duplicated = duplicate_deals[which.max(duplicate_deals$NumDuplicates)]
duplicate_deals = with_duplicates %>% group_by(Description) %>% summarise(NumDuplicates = length(Description)) %>% filter(NumDuplicates > 1)
most_duplicated = duplicate_deals[which.max(duplicate_deals$NumDuplicates)]
View(duplicate_deals)
most_duplicated = duplicate_deals[which.max(duplicate_deals$NumDuplicates),]
View(most_duplicated)
all_duplicates_Fry = deal_data[deal_data$Description == most_duplicated$Description, ]
View(all_duplicates_Fry)
deal_data$Description == most_duplicated$Description
all_duplicates_Fry = deal_data[with_duplicates$Description == most_duplicated$Description, ]
View(all_duplicates_Fry)
all_duplicates_Fry = with_duplicates[with_duplicates$Description == most_duplicated$Description, ]
View(all_duplicates_Fry)
nrow(with_duplicates[duplicated(deal_data),])
nrow(with_duplicates[duplicated(with_duplicates),])
nrow(with_duplicates[duplicated(with_duplicates[, c(Title, Description, Store),])
nrow(with_duplicates[duplicated(with_duplicates[, c(Title, Description, Store)]),])
nrow(with_duplicates[duplicated(with_duplicates[, c('Title', 'Description', 'Store')]),])
nrow(with_duplicates[duplicated(with_duplicates[, c('Category', 'Title', 'Description', 'Store')]),])
nrow(with_duplicates[duplicated(with_duplicates[, c('Category', 'Title', 'Description')]),])
deal_data = with_duplicates
with_duplicates = deal_data[!duplicated(deal_data$Description), ]
with_duplicates = deal_data[!duplicated(deal_data[, c('Category', 'Title', 'Description')]), ]
nrow(with_duplicates)
duplicate_deals = with_duplicates %>% group_by(Description) %>% summarise(NumDuplicates = length(Description)) %>% filter(NumDuplicates > 1)
range(duplicate_deals$NumDuplicates)
most_duplicated = duplicate_deals[which.max(duplicate_deals$NumDuplicates),]
all_duplicates_Fry = with_duplicates[with_duplicates$Description == most_duplicated$Description, ]
nrow(deal_data[duplicated(deal_data[, c('Category', 'Title', 'Description')]),])
without_duplicates = deal_data[!duplicated(deal_data[, c('Category', 'Title', 'Description')]), ]
nrow(without_duplicates)
duplicate_deals = without_duplicates %>% group_by(Description) %>% summarise(NumDuplicates = length(Description)) %>% filter(NumDuplicates > 1)
range(duplicate_deals$NumDuplicates)
most_duplicated = duplicate_deals[which.max(duplicate_deals$NumDuplicates),]
all_duplicates_Fry = deal_data[deal_data$Description == most_duplicated$Description, ]
View(all_duplicates_Fry)
write.csv(without_duplicates, 'Dealmoon_data/Non_duplicates.csv', row.names=F)
all_duplicates_Fry = deal_data[deal_data[, c('Category', 'Title', 'Description')] == most_duplicated[, c('Category', 'Title', 'Description')], ]
View(all_duplicates_Fry)
duplicate_deals = deal_data %>% group_by(Description) %>% summarise(NumDuplicates = length(Description)) %>% filter(NumDuplicates > 1)
most_duplicated = duplicate_deals[which.max(duplicate_deals$NumDuplicates),]
all_duplicates_Fry = deal_data[deal_data[, c('Category', 'Title', 'Description')] == most_duplicated[, c('Category', 'Title', 'Description')], ]
duplicate_deals = deal_data %>% group_by(Category, Title, Description) %>% summarise(NumDuplicates = length(Description)) %>% filter(NumDuplicates > 1)
range(duplicate_deals$NumDuplicates)
########## the number of duplicates range from 2 to 54
# visualise the deal with 54 duplicates
most_duplicated = duplicate_deals[which.max(duplicate_deals$NumDuplicates),]
all_duplicates_Fry = deal_data[deal_data[, c('Category', 'Title', 'Description')] == most_duplicated[, c('Category', 'Title', 'Description')], ]
shiny::runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
temp = without_duplicates %>% filter(Category = 'Beauty', Store = 'AMAZON')
temp = without_duplicates %>% filter(Category == 'Beauty', Store == 'AMAZON')
View(temp)
temp = without_duplicates %>% filter(Category == 'Beauty', Store == 'AMAZON') %>% select(PostedTime)
ts(temp)
plot.ts(ts(temp))
plot.ts(temp)
souvenirtimeseries <- ts(souvenir, frequency=12, start=c(1987,1))
souvenir <- scan("http://robjhyndman.com/tsdldata/data/fancy.dat")
souvenirtimeseries <- ts(souvenir, frequency=12, start=c(1987,1))
plot.ts(souvenirtimeseries)
temp = without_duplicates %>% filter(Category == 'Beauty', Store == 'AMAZON') %>% select(PostedTime) %>% group_by(PostedTime)
temp = without_duplicates %>% filter(Category == 'Beauty', Store == 'AMAZON') %>% select(PostedTime) %>% group_by(PostedTime) %>% n()
temp = without_duplicates %>% filter(Category == 'Beauty', Store == 'AMAZON') %>% select(PostedTime) %>% group_by(PostedTime) %>% summarise(n())
plot.ts(temp)
ts(temp)
temp = without_duplicates %>% filter(Category == 'Beauty', Store == 'AMAZON') %>% select(PostedTime) %>% group_by(PostedTime) %>% summarise(Count = n())
a = data.frame(temp$Count, row.names=temp$PostedTime)
a
plot.ts(a)
deal_data$PostedTime = as.Date('2016-08-13') - deal_data$PostedTime
deal_data
View(deal_data)
deal_data$PostedTime = as.Date('2016-08-13') + deal_data$PostedTime
write.csv(deal_data, 'Dealmoon_data/Deal_data2.csv', row.names=F)
deal_data$Popularity = deal_data$NumberOfComments + deal_data$NumberOfBookmarks
# check if there are deals that have the exact same 'Description'
nrow(deal_data[duplicated(deal_data[, c('Category', 'Title', 'Description')]),])
########## there are 1252 duplicates
# find non-duplicated rows
without_duplicates = deal_data[!duplicated(deal_data[, c('Category', 'Title', 'Description')]), ]
View(without_duplicates)
nrow(without_duplicates)
########## 44563 rows
# find duplicate rows and the number of duplicates
duplicate_deals = deal_data %>% group_by(Category, Title, Description) %>% summarise(NumDuplicates = length(Description)) %>% filter(NumDuplicates > 1)
range(duplicate_deals$NumDuplicates)
########## the number of duplicates range from 2 to 54
#
most_duplicated = duplicate_deals[which.max(duplicate_deals$NumDuplicates),]
write.csv(deal_data, 'Dealmoon_data/Deal_data.csv', row.names=F)
View(deal_data)
month(as.Date('2016-08-14'))
month(deal_data$PostedTime)
without_duplicates %>% month(PostedTime)
without_duplicates %>% month()
without_duplicates$PostedTime %>% month()
month(without_duplicates$PostedTime)
month_temp$Pos = month(month_temp$PostedTime)
month_temp = without_duplicates
month_temp$PostedTime = month(month_temp$PostedTime)
temp = month_temp %>% filter(Category == 'Beauty', Store == 'AMAZON') %>% select(PostedTime) %>% group_by(PostedTime) %>% summarise(Count = n())
ts(temp)
a = data.frame(temp$Count, row.names=temp$PostedTime)
plot.ts(a)
all_temp = without_duplicates %>% group_by(Category) %>% select(PostedTime) %>% month() %>% summarise(Count = n())
all_temp = without_duplicates %>% group_by(Category) %>% select(PostedTime) %>% summarise(Count = n())
all_temp = without_duplicates %>% group_by(Category) %>% select(PostedTime, Category) %>% summarise(Count = n())
View(all_temp)
all_temp = without_duplicates %>% transmute(PostedTime = month(PostedTime))
all_temp = all_temp %>% group_by(Category) %>% select(PostedTime, Category) %>% summarise(Count = n())
all_temp = without_duplicates %>% transmute(PostedTime = month(PostedTime))
all_temp = without_duplicates %>% mutate(PostedTime = month(PostedTime))
all_temp = all_temp %>% group_by(Category) %>% select(PostedTime, Category) %>% summarise(Count = n())
all_temp = all_temp %>% group_by(Category, PostedTime) %>% select(PostedTime, Category) %>% summarise(Count = n())
all_temp = without_duplicates %>% mutate(PostedTime = month(PostedTime))
all_temp = all_temp %>% group_by(Category, PostedTime) %>% select(PostedTime, Category) %>% summarise(Count = n())
b = data.frame(filter(all_temp, Category == 'Beauty')$Count, row.names=all_temp$PostedTime)
b = data.frame(filter(all_temp, Category == 'Beauty')$Count, row.names=filter(all_temp, Category == 'Beauty')$PostedTime)
plot.ts(b)
b = data.frame(filter(all_temp, Category == 'Baby')$Count, row.names=filter(all_temp, Category == 'Beauty')$PostedTime)
b = data.frame(filter(all_temp, Category == 'Baby')$Count, row.names=filter(all_temp, Category == 'Baby')$PostedTime)
plot.ts(b)
b = data.frame(filter(all_temp, Category == 'Clothing')$Count, row.names=filter(all_temp, Category == 'Baby')$PostedTime)
plot.ts(b)
b = data.frame(filter(all_temp, Category == cat)$Count, row.names=filter(all_temp, Category == cat )$PostedTime)
plot.ts(b)
cat = 'Clothing'
b = data.frame(filter(all_temp, Category == cat)$Count, row.names=filter(all_temp, Category == cat )$PostedTime)
plot.ts(b)
b = data.frame(filter(all_temp, Category == cate)$Count, row.names=filter(all_temp, Category == cate)$PostedTime)
cate = 'Clothing'
b = data.frame(filter(all_temp, Category == cate)$Count, row.names=filter(all_temp, Category == cate)$PostedTime)
plot.ts(b)
View(b)
cate = 'Travel'
b = data.frame(filter(all_temp, Category == cate)$Count, row.names=filter(all_temp, Category == cate)$PostedTime)
plot.ts(b)
cate = 'Electronics'
b = data.frame(filter(all_temp, Category == cate)$Count, row.names=filter(all_temp, Category == cate)$PostedTime)
plot.ts(b)
cate = 'Finance'
b = data.frame(filter(all_temp, Category == cate)$Count, row.names=filter(all_temp, Category == cate)$PostedTime)
plot.ts(b)
cate = 'Nutrition'
b = data.frame(filter(all_temp, Category == cate)$Count, row.names=filter(all_temp, Category == cate)$PostedTime)
plot.ts(b)
cate = 'Home'
b = data.frame(filter(all_temp, Category == cate)$Count, row.names=filter(all_temp, Category == cate)$PostedTime)
plot.ts(b)
without_duplicates %>% filter(Category == 'Electronics') %>% filter(month(PostedTime) == 11)
without_duplicates %>% filter(Category == 'Electronics') %>% filter(month(PostedTime) == 11) %>% select(Title)
without_duplicates %>% filter(Category == 'Electronics') %>% filter(month(PostedTime) == 11) %>% select(Description)
cate = 'Clothing'
b = data.frame(filter(all_temp, Category == cate)$Count, row.names=filter(all_temp, Category == cate)$PostedTime)
plot.ts(b)
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/AmyTzuyuChen/Mugapp')
install.packages("countrycode")
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/AmyTzuyuChen/Mugapp')
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/AmyTzuyuChen/Mugapp')
yday(as.Date('2016-08-23'))
mday(as.Date('2016-08-23'))
day_temp = without_duplicates %>% mutate(PostedTime = mday(PostedTime))
day_temp = day_temp %>% group_by(Category, PostedTime) %>% select(PostedTime, Category) %>% summarise(Count = n())
cate = 'Clothing'
b = data.frame(filter(day_temp, Category == cate)$Count, row.names=filter(day_temp, Category == cate)$PostedTime)
plot.ts(b)
cate = 'Baby'
b = data.frame(filter(day_temp, Category == cate)$Count, row.names=filter(day_temp, Category == cate)$PostedTime)
plot.ts(b)
cate = 'Electronics'
b = data.frame(filter(day_temp, Category == cate)$Count, row.names=filter(day_temp, Category == cate)$PostedTime)
plot.ts(b)
cate = 'Home'
b = data.frame(filter(day_temp, Category == cate)$Count, row.names=filter(day_temp, Category == cate)$PostedTime)
plot.ts(b)
cate = 'Travel'
b = data.frame(filter(day_temp, Category == cate)$Count, row.names=filter(day_temp, Category == cate)$PostedTime)
plot.ts(b)
cate = 'Beauty'
b = data.frame(filter(day_temp, Category == cate)$Count, row.names=filter(day_temp, Category == cate)$PostedTime)
plot.ts(b)
cate = 'Clothing'
b = data.frame(filter(day_temp, Category == cate)$Count, row.names=filter(day_temp, Category == cate)$PostedTime)
plot.ts(b)
View(Top_5_deal)
Top_5_deal$Title
Top_5_deal = deal_data %>% group_by(Category) %>% top_n(5, Popularity) %>% select(Category, PostedTime, Title, Description, Popularity)
Top_5_deal$Description
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
unique(without_duplicates$Category)
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
unique(without_duplicates$Category)
View(with_duplicates)
rm(with_duplicates)
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
View(without_duplicates)
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
popular_data = without_duplicates %>% select(Category, Title, Description) %>% filter(Category == input$PopularCategory)
order(popular_data, 'Popularity', decreasing = T)
popular_data = without_duplicates %>% select(Category, Title, Description) %>% filter(Category == 'Baby')
order(popular_data, 'Popularity', decreasing = T)
popular_data[order('Popularity', decreasing = T),]
popular_data[order('Popularity', decreasing = T), ]
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
mtcars[order(mpg),]
mpg
attach(mtcars)
mtcars[order(mpg),]
popular_data[order('Popularity', decreasing = T), ]
View(popularity_data)
View(popular_data)
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
popular_data = without_duplicates %>% select(Category, Title, Description, Popularity = Popularity) %>% filter(Category == input$PopularCategory)
popular_data = without_duplicates %>% select(Category, Title, Description, Popularity = Popularity) %>% filter(Category == 'Baby')
popular_data[order('Popularity', decreasing = T), ]
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
View(popularity_overall)
View(popularity_data)
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
View(master_popularity_data)
master_popularity_data$PPD = master_popularity_data$Popularity / master_popularity_data$NumDeals
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
Cairo
header(Cairo)
head(Cairo)
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
View(without_duplicates)
View(popularity_data)
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
head(Stock)
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
without_duplicates$PostedTime = as.Date('2016-08-13') - without_duplicates$PostedTime
View(without_duplicates)
without_duplicates$PostedTime = as.Date('2016-08-13') + without_duplicates$PostedTime
View(without_duplicates)
write.csv(without_duplicates, 'Dealmoon_data/Non_duplicates.csv', row.names=F)
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
if (!require(shinysky)) install.packages(shinysky)
install.packages("ShinySky")
if (require(devtools)) install.packages("devtools")#if not alrady installed
devtools::install_github("AnalytixWare/ShinySky")
library(shinysky)
install.packages("devtools")
devtools::install_github("ThomasSiegmund/shinyTypeahead")
if (require(devtools)) install.packages("devtools")#if not alrady installed
devtools::install_github("AnalytixWare/ShinySky")
install.packages("devtools")
library(shinysky)
View(master_popularity_data)
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
if (!require(reshape2)) install.packages(reshape2)
runApp('~/GitHub/bootcamp006_project/Project3-WebScraping/JieleiZhu/App')
install.packages("devtools")
shiny::runApp()
install.packages("devtools")
runApp()
runApp()
runApp()
runApp()
runApp()
conflicts()
detach("package:plyr", unload=TRUE)
runApp()
runApp()
runApp()
runApp()
runApp()
